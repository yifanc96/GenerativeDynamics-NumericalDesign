{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d8253a0-b065-42c9-9625-57bed26c074f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data\n",
    "from torch.utils.data import DataLoader \n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import wandb\n",
    "import math\n",
    "import argparse\n",
    "import datetime\n",
    "import math\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b9072872-b542-4479-b419-9afb72710a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_twomode_GMM(num_samples, dim, p, r, sigma=1.0, device='cpu', dtype=torch.float32, seed=None):\n",
    "    \"\"\"\n",
    "    Generate samples from a bimodal Gaussian mixture model in d dimensions using PyTorch.\n",
    "    \n",
    "    The mixture is defined as:\n",
    "    ρ*(x) = p*N(x; r, I_d) + (1-p)*N(x; -r, I_d)\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    num_samples : int\n",
    "        Number of samples to generate\n",
    "    dim : int\n",
    "        Dimensionality of the data\n",
    "    p : float\n",
    "        Mixing probability for the first component (0 ≤ p ≤ 1)\n",
    "    r : array-like, tensor, or float\n",
    "        Fixed vector for the means. If float, creates vector (r, r, ..., r)\n",
    "    sigma : float, default=1.0\n",
    "        Standard deviation for each component\n",
    "    device : str or torch.device, default='cpu'\n",
    "        Device to place tensors on\n",
    "    dtype : torch.dtype, default=torch.float32\n",
    "        Data type for the tensors\n",
    "    seed : int, optional\n",
    "        Random seed for reproducibility\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    samples : torch.Tensor of shape (num_samples, dim)\n",
    "        Generated samples from the mixture\n",
    "    labels : torch.Tensor of shape (num_samples,)\n",
    "        Component labels (0 for first component, 1 for second component)\n",
    "    \"\"\"\n",
    "    \n",
    "    if seed is not None:\n",
    "        torch.manual_seed(seed)\n",
    "    \n",
    "    # Handle r parameter\n",
    "    if torch.is_tensor(r):\n",
    "        r_vec = r.to(device=device, dtype=dtype)\n",
    "    elif hasattr(r, '__len__'):  # array-like\n",
    "        r_vec = torch.tensor(r, device=device, dtype=dtype)\n",
    "    else:  # scalar\n",
    "        r_vec = torch.full((dim,), r, device=device, dtype=dtype)\n",
    "    \n",
    "    # Generate component assignments\n",
    "    component_labels = torch.bernoulli(torch.full((num_samples,), 1-p, device=device, dtype=dtype)).long()\n",
    "    \n",
    "    # Generate samples\n",
    "    samples = torch.zeros(num_samples, dim, device=device, dtype=dtype)\n",
    "    \n",
    "    # First component: N(x; r, σ²I_d)\n",
    "    first_mask = (component_labels == 0)\n",
    "    if first_mask.any():\n",
    "        samples[first_mask] = torch.normal(\n",
    "            mean=r_vec.unsqueeze(0).expand(first_mask.sum(), -1),\n",
    "            std=sigma\n",
    "        )\n",
    "    \n",
    "    # Second component: N(x; -r, σ²I_d)\n",
    "    second_mask = (component_labels == 1)\n",
    "    if second_mask.any():\n",
    "        samples[second_mask] = torch.normal(\n",
    "            mean=-r_vec.unsqueeze(0).expand(second_mask.sum(), -1),\n",
    "            std=sigma\n",
    "        )\n",
    "    \n",
    "    return samples, component_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d1e80e8-43e5-4a94-90c4-1fdf21a88901",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### standard interpolants\n",
    "    \n",
    "def beta(t):\n",
    "    return t\n",
    "\n",
    "def beta_dot(t):\n",
    "    return 1.0 \n",
    "\n",
    "#### designed interpolants\n",
    "\n",
    "M = 100\n",
    "\n",
    "\n",
    "import torch\n",
    "\n",
    "def beta(t):\n",
    "    \"\"\"\n",
    "    Compute β_t = (1/M) * √(-log(1 + (e^(-M²) - 1)t))\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    t : float or torch.Tensor\n",
    "        Time parameter\n",
    "    M : float or torch.Tensor\n",
    "        Parameter M\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    torch.Tensor\n",
    "        β_t(t) value\n",
    "    \"\"\"\n",
    "    t = torch.as_tensor(t, dtype=torch.float32)\n",
    "    M_squared = torch.as_tensor(M*M, dtype=torch.float32)\n",
    "    \n",
    "    # For numerical stability when M² is large\n",
    "    if M_squared > 20:\n",
    "        # e^(-M²) ≈ 0, so (e^(-M²) - 1) ≈ -1\n",
    "        inner = 1 - t\n",
    "    else:\n",
    "        exp_neg_M2 = torch.exp(-M_squared)\n",
    "        inner = 1 + (exp_neg_M2 - 1) * t\n",
    "    \n",
    "    # Clamp to avoid log(0) or negative values\n",
    "    inner = torch.clamp(inner, min=1e-10)\n",
    "    log_term = -torch.log(inner)\n",
    "    \n",
    "    beta = torch.sqrt(torch.clamp(log_term, min=1e-10)) / M\n",
    "    \n",
    "    return beta\n",
    "\n",
    "def beta_dot(t):\n",
    "    \"\"\"\n",
    "    Compute dβ_t/dt = -(1/M) * (e^(-M²) - 1) / (2 * √(-log(1 + (e^(-M²) - 1)t)) * (1 + (e^(-M²) - 1)t))\n",
    "    \n",
    "    Mathematical derivation:\n",
    "    β_t = (1/M) * √(-log(1 + (e^(-M²) - 1)t))\n",
    "    \n",
    "    Let u = 1 + (e^(-M²) - 1)t\n",
    "    Then β_t = (1/M) * √(-log(u))\n",
    "    \n",
    "    dβ_t/dt = (1/M) * (1/2) * (1/√(-log(u))) * d/dt[-log(u)]\n",
    "            = (1/M) * (1/2) * (1/√(-log(u))) * (-1/u) * du/dt\n",
    "            = (1/M) * (1/2) * (1/√(-log(u))) * (-1/u) * (e^(-M²) - 1)\n",
    "            = -(1/M) * (e^(-M²) - 1) / (2 * √(-log(u)) * u)\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    t : float or torch.Tensor\n",
    "        Time parameter\n",
    "    M : float or torch.Tensor\n",
    "        Parameter M\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    torch.Tensor\n",
    "        dβ_t/dt value\n",
    "    \"\"\"\n",
    "    t = torch.as_tensor(t, dtype=torch.float32)\n",
    "    M_squared = torch.as_tensor(M*M, dtype=torch.float32)\n",
    "    \n",
    "    # For numerical stability when M² is large\n",
    "    if M_squared > 20:\n",
    "        # e^(-M²) ≈ 0, so (e^(-M²) - 1) ≈ -1\n",
    "        exp_term = -1.0\n",
    "        inner = 1 - t\n",
    "    else:\n",
    "        exp_neg_M2 = torch.exp(-M_squared)\n",
    "        exp_term = exp_neg_M2 - 1\n",
    "        inner = 1 + exp_term * t\n",
    "    \n",
    "    # Clamp to avoid numerical issues\n",
    "    inner = torch.clamp(inner, min=1e-10)\n",
    "    log_term = -torch.log(inner)\n",
    "    sqrt_log_term = torch.sqrt(torch.clamp(log_term, min=1e-10))\n",
    "    \n",
    "    # Compute derivative - the negative sign is crucial!\n",
    "    derivative = -(1/M) * exp_term / (2 * sqrt_log_term * inner)\n",
    "    \n",
    "    return derivative\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc28114d-66fd-4087-bf7c-b4c9c689f599",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # test derivatives of beta\n",
    "\n",
    "# def beta(t, M):\n",
    "#     \"\"\"\n",
    "#     Compute β_t = (1/M) * √(-log(1 + (e^(-M²) - 1)t))\n",
    "    \n",
    "#     Parameters:\n",
    "#     -----------\n",
    "#     t : float or torch.Tensor\n",
    "#         Time parameter\n",
    "#     M : float or torch.Tensor\n",
    "#         Parameter M\n",
    "        \n",
    "#     Returns:\n",
    "#     --------\n",
    "#     torch.Tensor\n",
    "#         β_t(t) value\n",
    "#     \"\"\"\n",
    "#     t = torch.as_tensor(t, dtype=torch.float32)\n",
    "#     M = torch.as_tensor(M, dtype=torch.float32)\n",
    "#     M_squared = M * M\n",
    "    \n",
    "#     # For numerical stability when M² is large\n",
    "#     if M_squared > 20:\n",
    "#         # e^(-M²) ≈ 0, so (e^(-M²) - 1) ≈ -1\n",
    "#         inner = 1 - t\n",
    "#     else:\n",
    "#         exp_neg_M2 = torch.exp(-M_squared)\n",
    "#         inner = 1 + (exp_neg_M2 - 1) * t\n",
    "    \n",
    "#     # Clamp to avoid log(0) or negative values\n",
    "#     inner = torch.clamp(inner, min=1e-10)\n",
    "#     log_term = -torch.log(inner)\n",
    "    \n",
    "#     beta = torch.sqrt(torch.clamp(log_term, min=1e-10)) / M\n",
    "    \n",
    "#     return beta\n",
    "\n",
    "# def beta_dot(t, M):\n",
    "#     \"\"\"\n",
    "#     Compute dβ_t/dt = -(1/M) * (e^(-M²) - 1) / (2 * √(-log(1 + (e^(-M²) - 1)t)) * (1 + (e^(-M²) - 1)t))\n",
    "    \n",
    "#     Mathematical derivation:\n",
    "#     β_t = (1/M) * √(-log(1 + (e^(-M²) - 1)t))\n",
    "    \n",
    "#     Let u = 1 + (e^(-M²) - 1)t\n",
    "#     Then β_t = (1/M) * √(-log(u))\n",
    "    \n",
    "#     dβ_t/dt = (1/M) * (1/2) * (1/√(-log(u))) * d/dt[-log(u)]\n",
    "#             = (1/M) * (1/2) * (1/√(-log(u))) * (-1/u) * du/dt\n",
    "#             = (1/M) * (1/2) * (1/√(-log(u))) * (-1/u) * (e^(-M²) - 1)\n",
    "#             = -(1/M) * (e^(-M²) - 1) / (2 * √(-log(u)) * u)\n",
    "    \n",
    "#     Parameters:\n",
    "#     -----------\n",
    "#     t : float or torch.Tensor\n",
    "#         Time parameter\n",
    "#     M : float or torch.Tensor\n",
    "#         Parameter M\n",
    "        \n",
    "#     Returns:\n",
    "#     --------\n",
    "#     torch.Tensor\n",
    "#         dβ_t/dt value\n",
    "#     \"\"\"\n",
    "#     t = torch.as_tensor(t, dtype=torch.float32)\n",
    "#     M = torch.as_tensor(M, dtype=torch.float32)\n",
    "#     M_squared = M * M\n",
    "    \n",
    "#     # For numerical stability when M² is large\n",
    "#     if M_squared > 20:\n",
    "#         # e^(-M²) ≈ 0, so (e^(-M²) - 1) ≈ -1\n",
    "#         exp_term = -1.0\n",
    "#         inner = 1 - t\n",
    "#     else:\n",
    "#         exp_neg_M2 = torch.exp(-M_squared)\n",
    "#         exp_term = exp_neg_M2 - 1\n",
    "#         inner = 1 + exp_term * t\n",
    "    \n",
    "#     # Clamp to avoid numerical issues\n",
    "#     inner = torch.clamp(inner, min=1e-10)\n",
    "#     log_term = -torch.log(inner)\n",
    "#     sqrt_log_term = torch.sqrt(torch.clamp(log_term, min=1e-10))\n",
    "    \n",
    "#     # Compute derivative - the negative sign is crucial!\n",
    "#     derivative = -(1/M) * exp_term / (2 * sqrt_log_term * inner)\n",
    "    \n",
    "#     return derivative\n",
    "\n",
    "# # Test function to verify the derivative numerically\n",
    "# def test_derivative(t_val, M_val, h=1e-6):\n",
    "#     \"\"\"Numerical derivative test\"\"\"\n",
    "#     t_tensor = torch.tensor(t_val, dtype=torch.float32)\n",
    "    \n",
    "#     # Numerical derivative\n",
    "#     beta_plus = beta(t_tensor + h, M_val)\n",
    "#     beta_minus = beta(t_tensor - h, M_val)\n",
    "#     numerical_deriv = (beta_plus - beta_minus) / (2 * h)\n",
    "    \n",
    "#     # Analytical derivative\n",
    "#     analytical_deriv = beta_dot(t_tensor, M_val)\n",
    "    \n",
    "#     print(f\"t={t_val}, M={M_val}\")\n",
    "#     print(f\"Numerical derivative: {numerical_deriv.item():.6f}\")\n",
    "#     print(f\"Analytical derivative: {analytical_deriv.item():.6f}\")\n",
    "#     print(f\"Relative error: {abs(numerical_deriv - analytical_deriv) / abs(numerical_deriv):.2e}\")\n",
    "#     print()\n",
    "\n",
    "# # Example usage and testing\n",
    "# if __name__ == \"__main__\":\n",
    "#     # Test with different values\n",
    "#     test_derivative(1e-6, 10000.0)\n",
    "#     test_derivative(0.5, 10000)\n",
    "#     test_derivative(0.9, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae2dd37c-cced-46e2-9e25-722a9e668ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def drift_b(x, t, r, h):\n",
    "    \"\"\"\n",
    "    Compute b_t(x) = dotβ_t(t) * tanh(h + β_t(t) * ⟨r, x⟩)\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    x : torch.Tensor of shape (num_samples, d)\n",
    "        Input points \n",
    "    r : torch.Tensor of shape (d,)\n",
    "        Fixed vector satisfying |r|_2 = sqrt(d)\n",
    "    beta_t : callable\n",
    "        Function that takes time t and returns β_t(t)\n",
    "    h : float or torch.Tensor\n",
    "        Scalar parameter h in the tanh function\n",
    "    t : float or torch.Tensor\n",
    "        Current time value\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    torch.Tensor of shape (num_samples, d)\n",
    "        b_t(x) evaluated at input points x\n",
    "    \"\"\"\n",
    "    \n",
    "    # Evaluate β_t at time t\n",
    "    beta_val = beta(t)\n",
    "    dot_beta = beta_dot(t)\n",
    "    \n",
    "    # Compute inner product ⟨r, x⟩ for each sample\n",
    "    inner_product = torch.sum(x * r, dim=1, keepdim=True)  # (num_samples, 1)\n",
    "    \n",
    "    # Compute β_t * ⟨r, x⟩\n",
    "    beta_inner = beta_val * inner_product  # (num_samples, 1)\n",
    "    \n",
    "    # Compute tanh(h + β_t * ⟨r, x⟩)\n",
    "    tanh_term = torch.tanh(h + beta_inner)  # (num_samples, 1)\n",
    "    \n",
    "    # Compute b_t(x) = dotβ_t * tanh(h + β_t * ⟨r, x⟩) * r\n",
    "    bt_x = dot_beta * tanh_term * r.unsqueeze(0)  # (num_samples, d)\n",
    "    \n",
    "    return bt_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3035aef-9589-49f2-a745-4dd0c249f3ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 100000\n",
    "dim = 1\n",
    "r = torch.ones(1)*M\n",
    "p = 0.3\n",
    "h = math.log(p/(1-p))/2\n",
    "z0 = torch.randn(num_samples, dim)\n",
    "z1, _ = generate_twomode_GMM(num_samples, dim, p, r, sigma=1.0)\n",
    "\n",
    "D = {'z0': z0, 'z1': z1}\n",
    "\n",
    "t_min_sample = 1e-3\n",
    "t_max_sample = 1-1e-3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb08ec2f-b648-493c-a817-13bc7103b39a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## RK integration\n",
    "\n",
    "from torchdiffeq import odeint\n",
    "class PFlowRHS(nn.Module):\n",
    "    def __init__(self, drift_b, r, h):\n",
    "        super(PFlowRHS, self).__init__()\n",
    "        self.drift_b = drift_b\n",
    "        self.r = r\n",
    "        self.h = h\n",
    "        \n",
    "    def forward(self, t, states):\n",
    "        (zt,) = states\n",
    "        dzt = self.drift_b(zt, t, self.r, self.h)\n",
    "        return (dzt,)\n",
    "             \n",
    "class PFlowIntegrator:\n",
    "        \n",
    "    def __init__(self):\n",
    "        return        \n",
    "\n",
    "    def __call__(self, drift_b, z0, r, h, T_min, T_max, steps, method='dopri5', return_last = True):\n",
    "\n",
    "        rhs = PFlowRHS(drift_b, r, h)\n",
    "\n",
    "        t = torch.linspace(\n",
    "            T_min, T_max, steps\n",
    "        ).type_as(z0)\n",
    "\n",
    "        int_args = {\n",
    "            'method': method, \n",
    "            # 'atol': c.integration_atol, \n",
    "            # 'rtol': c.integration_rtol,\n",
    "        }\n",
    "\n",
    "        (z,) = odeint(rhs, (z0,), t, **int_args)\n",
    "        if return_last:\n",
    "            return z[-1].clone()\n",
    "        else:\n",
    "            return z\n",
    "\n",
    "pflow = PFlowIntegrator()\n",
    "\n",
    "out = pflow(\n",
    "    drift_b = drift_b,\n",
    "    z0 = D['z0'],\n",
    "    r = r, \n",
    "    h = h, \n",
    "    T_min = t_min_sample,\n",
    "    T_max = t_max_sample,\n",
    "    steps = 5, \n",
    "    method = 'rk4',\n",
    "    return_last = True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a51d9ae3-6ab5-4439-af17-27a6394e587e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def fit_gmm_density(samples, n_components=2, use_pca=True):\n",
    "    \"\"\"\n",
    "    Fit GMM to samples and return parameters.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    samples : torch.Tensor of shape (num_samples, dim)\n",
    "        Input samples\n",
    "    n_components : int, default=2\n",
    "        Number of GMM components\n",
    "    use_pca : bool, default=True\n",
    "        Apply PCA if dim > 2\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    weights : np.ndarray\n",
    "        Component weights\n",
    "    means : np.ndarray\n",
    "        Component means\n",
    "    covariances : np.ndarray\n",
    "        Component covariances\n",
    "    \"\"\"\n",
    "    \n",
    "    # Convert to numpy\n",
    "    if torch.is_tensor(samples):\n",
    "        samples = samples.detach().cpu().numpy()\n",
    "    \n",
    "    # Apply PCA if high-dimensional\n",
    "    if use_pca and samples.shape[1] > 2:\n",
    "        pca = PCA(n_components=2)\n",
    "        samples = pca.fit_transform(samples)\n",
    "        print(f\"PCA: {pca.explained_variance_ratio_.sum():.1%} variance explained\")\n",
    "    \n",
    "    # Fit GMM\n",
    "    gmm = GaussianMixture(n_components=n_components, random_state=42)\n",
    "    gmm.fit(samples)\n",
    "    \n",
    "    # Print parameters\n",
    "    print(f\"Weights: {gmm.weights_}\")\n",
    "    print(f\"Means:\\n{gmm.means_}\")\n",
    "    print(f\"Covariances:\\n{gmm.covariances_}\")\n",
    "    \n",
    "    return gmm.weights_, gmm.means_, gmm.covariances_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "7d8fc070-946a-458f-8d39-c64b9726489a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "truth\n",
      "Weights: [0.70046 0.29954]\n",
      "Means:\n",
      "[[-100.00101839]\n",
      " [  99.9985427 ]]\n",
      "Covariances:\n",
      "[[[0.99856299]]\n",
      "\n",
      " [[0.9960062 ]]]\n",
      "---------------------------------\n",
      "generation\n",
      "Weights: [0.9721 0.0279]\n",
      "Means:\n",
      "[[-97.97586441]\n",
      " [ 92.58937739]]\n",
      "Covariances:\n",
      "[[[1.62630542]]\n",
      "\n",
      " [[4.54553139]]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print('truth')\n",
    "weights, means, covariances = fit_gmm_density(z1, n_components=2, use_pca=False)\n",
    "print('---------------------------------')\n",
    "print('generation')\n",
    "weights, means, covariances = fit_gmm_density(out, n_components=2, use_pca=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dadf3d5-adde-47a5-b4be-f92168e51183",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8289bc6-d7ce-4d64-a4fa-273cf8a4223e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd97309-f2da-4d7a-a81a-1925addb3f23",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MYKERNEL",
   "language": "python",
   "name": "my_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
