{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d678cd0-5900-44ff-a914-a7d98af31360",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data\n",
    "from torch.utils.data import DataLoader\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import wandb\n",
    "import math\n",
    "import argparse\n",
    "import datetime\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8dab28c1-1f48-4e9f-aab3-59eb2a9b32d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "################ generate data ###############\n",
    "\n",
    "# generating Gaussian measure on torus; diagonizable in Fourier\n",
    "\n",
    "def generate_matern_laplace1d(num_samples, grid_size, sigma_sq=1.0, length_scale=1.0, s=2.0, seed=None):\n",
    "    \"\"\"\n",
    "    Generate Matérn GP using the operator form σ²(-Δ + l²I)^{-s}\n",
    "    \n",
    "    Args:\n",
    "        grid_size (int): Size of the grid (N x N)\n",
    "        sigma_sq (float): Variance parameter σ²\n",
    "        length_scale (float): Length scale l\n",
    "        s (float): Smoothness parameter s\n",
    "        seed (int): Random seed for reproducibility\n",
    "    \n",
    "    Returns:\n",
    "        torch.Tensor: Sample from the GP\n",
    "    \"\"\"\n",
    "    if seed is not None:\n",
    "        torch.manual_seed(seed)\n",
    "    \n",
    "    # Generate frequency grid (scaled by 2π)\n",
    "    freq = torch.fft.fftfreq(grid_size) * 2 * math.pi * grid_size\n",
    "    \n",
    "    # Compute -Laplacian in Fourier space: |k|²\n",
    "    laplacian = freq**2\n",
    "    \n",
    "    # Compute spectral density: σ²(|k|² + l²)^{-s}\n",
    "    spectral_density = sigma_sq * (laplacian + length_scale**2)**(-s)\n",
    "    spectral_density = spectral_density.unsqueeze(0)  # adding 1 dim\n",
    "    \n",
    "    # Generate complex Gaussian noise\n",
    "    noise_real = torch.randn(num_samples, grid_size)\n",
    "    noise_imag = torch.randn(num_samples, grid_size)\n",
    "    noise = noise_real + 1j * noise_imag\n",
    "    \n",
    "    # Apply sqrt of spectral density\n",
    "    spectral_sample = torch.sqrt(spectral_density) * noise\n",
    "    \n",
    "    # Transform back to spatial domain\n",
    "    sample = torch.fft.ifft(spectral_sample, norm='forward')\n",
    "    sample = sample.real\n",
    "    \n",
    "    return sample[:,None,...]\n",
    "\n",
    "# Example usage\n",
    "\n",
    "# grid_size = 64\n",
    "\n",
    "# sample = generate_matern_laplace1d(\n",
    "#     num_samples=1000,\n",
    "#     grid_size=grid_size,\n",
    "#     sigma_sq=1,\n",
    "#     length_scale=1.0,\n",
    "#     s=3,\n",
    "#     seed=42\n",
    "# )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d065050-5c5b-4111-b86f-6b5f7f786533",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa7c467d-f7d0-46b6-8900-7cc19264d1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "################ data loader ################\n",
    "\n",
    "def get_AllenCahn_dataloader(grid_size, batch_size, train_test_split, subsampling_ratio = None, loc=\"./data/\"):\n",
    "    \"\"\"\n",
    "    get dataloader for 2D Allen Cahn\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    grid_size: resolutions of the field\n",
    "    batch_size: batch size\n",
    "    train_test_split: a ratio representing the splitting of training/testing data\n",
    "    subsampling_ratio: used for subsampling a small portion of data, for convenient small scale experiments\n",
    "    \"\"\"\n",
    "    loc = loc + f\"AllenCahn1D_grid{grid_size}_samples.npy\"\n",
    "    \n",
    "    data_raw = np.load(loc)\n",
    "    print(f\"[Data] raw data shape is {data_raw.shape}\")\n",
    "    torch_data = torch.from_numpy(data_raw)\n",
    "    torch_data = torch.reshape(torch_data, (-1,torch_data.shape[-1]))\n",
    "    print(f\"[Data] flattened torchdata, shape is {torch_data.shape}\")\n",
    "    norm_per_pixel = torch.norm(torch_data,dim=(1),p='fro').mean()/torch_data.shape[-1]\n",
    "    print(f\"[Data] norm per pixel {norm_per_pixel}\")\n",
    "\n",
    "    if subsampling_ratio:\n",
    "        torch_data = torch_data[:int(subsampling_ratio*torch_data.size()[0]),...]\n",
    "\n",
    "    num_train = int(torch_data.size()[0]*train_test_split)\n",
    "    print(f'---- [processing] train_test_split {train_test_split}, num of training {num_train}, testing {torch_data.size()[0]-num_train}')\n",
    "    \n",
    "    train_loader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(torch_data[:num_train,None,:grid_size].float()), batch_size=batch_size, shuffle=True)\n",
    "    test_loader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(torch_data[num_train:,None,:grid_size].float()), batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    return train_loader, test_loader, norm_per_pixel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05d8dd6a-c99c-4afa-8b1e-19a3c7f536ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid_size = 64\n",
    "# batch_size = 1000\n",
    "# train_test_split = 0.9\n",
    "\n",
    "# train_loader, test_loader, norm_per_pixel = get_AllenCahn_dataloader(grid_size, batch_size, train_test_split, subsampling_ratio = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f5ae3a08-22bd-460e-8295-414b69770485",
   "metadata": {},
   "outputs": [],
   "source": [
    "################ network ################\n",
    "\n",
    "from unet1D import Unet1D\n",
    "class Velocity(nn.Module):\n",
    "    \"\"\" \n",
    "    This is a wrapper around any architecture\n",
    "    The warpper handles the additional conditioning input by appending conditioning input as a channel\n",
    "    \"\"\"\n",
    "    def __init__(self, config):\n",
    "        super(Velocity, self).__init__()\n",
    "        self.config = config\n",
    "        self._arch = Unet1D(\n",
    "            config.unet_channels,\n",
    "            dim_mults=config.unet_dim_mults,\n",
    "            channels = config.C + config.cond_channels,\n",
    "            out_dim = config.C,\n",
    "            learned_sinusoidal_cond = config.unet_learned_sinusoidal_cond,\n",
    "            random_fourier_features = config.unet_random_fourier_features,\n",
    "        )\n",
    "        num_params = np.sum([int(np.prod(p.shape)) for p in self._arch.parameters()])\n",
    "        print(\"[Network] Num params in main arch for velocity is\", f\"{num_params:,}\")\n",
    "\n",
    "    def forward(self, zt, t, cond=None):\n",
    "        inputs = zt\n",
    "        if cond is not None:\n",
    "            \"\"\"appending conditioning input as a channel\"\"\" \n",
    "            inputs = torch.cat([inputs, cond], dim=1)\n",
    "        out = self._arch(inputs, t)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ebe50ec2-1639-4306-8784-c3486e7b642e",
   "metadata": {},
   "outputs": [],
   "source": [
    "################ interpolants and sampler ################\n",
    "\n",
    "class Interpolants:\n",
    "    \n",
    "    \"\"\" \n",
    "    Definition of interpolants\n",
    "    I_t = alpha x_0 + beta x_1 (x_0 is Gaussian base)\n",
    "    R_t = alpha_dot x_0 + beta_dot x_1\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, config):\n",
    "        super(Interpolants, self).__init__()\n",
    "        self.config = config\n",
    "        \n",
    "    def alpha(self, t):\n",
    "        return 1-t\n",
    "\n",
    "    def alpha_dot(self, t):\n",
    "        return -1.0 * torch.ones_like(t)\n",
    "\n",
    "    def beta(self, t):\n",
    "        return t\n",
    "\n",
    "    def beta_dot(self, t):\n",
    "        return 1.0 * torch.ones_like(t)\n",
    "    \n",
    "    def wide(self, x):\n",
    "        return x[:, None, None]\n",
    "\n",
    "    def It(self, D):\n",
    "        \"\"\"\n",
    "        D is a dictionary containing \n",
    "        x0 = z0, \n",
    "        x1 = z1, \n",
    "        zt = I_t = alpha x_0 + beta x_1\n",
    "        \"\"\"\n",
    "        z0 = D['z0']\n",
    "        z1 = D['z1']\n",
    "        t = D['t']\n",
    "\n",
    "        aterm = self.wide(self.alpha(t)) * z0\n",
    "        bterm = self.wide(self.beta(t)) * z1\n",
    "\n",
    "        D['zt'] = aterm + bterm\n",
    "        return D\n",
    "\n",
    "    def Rt(self, D):\n",
    "        \"\"\"\n",
    "        D is a dictionary containing \n",
    "        x0 = z0, \n",
    "        x1 = z1, \n",
    "        R_t = alpha_dot x_0 + beta_dot x_1\n",
    "        \"\"\"\n",
    "        z0 = D['z0']\n",
    "        z1 = D['z1']\n",
    "        t = D['t']\n",
    "\n",
    "        adot = self.wide(self.alpha_dot(t))\n",
    "        bdot = self.wide(self.beta_dot(t))\n",
    "        return (adot * z0) + (bdot * z1)\n",
    "\n",
    "\n",
    "class Sampler:\n",
    "    \"\"\"\n",
    "    sampler \n",
    "    self.interpolant: get information from the defined interpolants\n",
    "    self.logger: information for uploading results to wandb, used in self.log_wandb_figure\n",
    "    self.EM: EM for sampling\n",
    "    \"\"\"\n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "        self.logger = Loggers(config)\n",
    "        self.interpolant = Interpolants(config)\n",
    "        return\n",
    "    \n",
    "    def wide(self, x):\n",
    "        return x[:, None, None, None]\n",
    "\n",
    "    def EM(self, D, model, steps = 200):  # here it is EM, for improved performance, should use odeint\n",
    "        print('[Sampler] Use EM samplers')\n",
    "        init_condition = D['z0']\n",
    "        tgrid = torch.linspace(self.config.t_min_sample, self.config.t_max_sample, steps).type_as(init_condition)\n",
    "        dt = tgrid[1] - tgrid[0]\n",
    "        zt = D['z0']\n",
    "        cond = D['cond']\n",
    "        ones = torch.ones(zt.shape[0]).type_as(zt)\n",
    "        for tscalar in tgrid:\n",
    "            t_arr = tscalar * ones\n",
    "            f = model(zt, t_arr, cond = cond) # note we condiition on init cond\n",
    "            zt_mean = zt + f * dt\n",
    "            zt = zt_mean\n",
    "        return zt_mean\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def sample(self, D, model, global_step):\n",
    "        model.eval()\n",
    "        zT = self.EM(D, model)     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2c5d445e-9282-4a50-80d4-25cb3d74ce6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "def get_energy_spectrum1d(vorticity_trajectory):\n",
    "    vorticity_hat = torch.fft.fft(vorticity_trajectory,dim=(1),norm = \"forward\")\n",
    "    fourier_amplitudes = np.abs(vorticity_hat)**2 \n",
    "    fourier_amplitudes = fourier_amplitudes.mean(dim=0)\n",
    "    npix = vorticity_hat.shape[-1]\n",
    "    kfreq = np.fft.fftfreq(npix) * npix\n",
    "    knrm = np.sqrt(kfreq**2)\n",
    "    knrm = knrm.flatten()\n",
    "    fourier_amplitudes = fourier_amplitudes.flatten()\n",
    "    \n",
    "    kvals = knrm\n",
    "    Abins_w = fourier_amplitudes\n",
    "    \n",
    "    return kvals, Abins_w\n",
    "\n",
    "def plot_spectra(trajectory_1,trajectory_2, save_name = './energy_spectrum.jpg'):\n",
    "    \n",
    "    kvals, Abins_w1 = get_energy_spectrum1d(trajectory_1)\n",
    "    kvals, Abins_w2 = get_energy_spectrum1d(trajectory_2)\n",
    "    \n",
    "    fig = plt.figure(figsize=(5,5))\n",
    "    plt.plot(kvals, Abins_w1, label = 'spectrum of truth')\n",
    "    plt.plot(kvals, Abins_w2, '--', label = 'spectrum of generated')\n",
    "    plt.xscale('log')\n",
    "    plt.yscale('log')\n",
    "    plt.legend()\n",
    "    plt.savefig(save_name,dpi=300, bbox_inches='tight', transparent=True,facecolor='w')\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd80333d-17d1-4bda-ac8a-e895c628c1af",
   "metadata": {},
   "outputs": [],
   "source": [
    "################ trainer ################\n",
    "\n",
    "class Trainer:\n",
    "    \"\"\"\n",
    "    Trainer\n",
    "    self.time_dist: used for sampling time during training\n",
    "    \"\"\"\n",
    "    def __init__(self, config):\n",
    "        super(Trainer, self).__init__()\n",
    "        self.config = config\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.interpolant = Interpolants(self.config)\n",
    "        self.model = Velocity(self.config)\n",
    "        self.model.to(self.device)\n",
    "        self.optimizer = self.get_optimizer(config)\n",
    "        self.sampler = Sampler(config)\n",
    "        self.time_dist = torch.distributions.Uniform(low=self.config.t_min_train, high=self.config.t_max_train)\n",
    "        self.global_step = 0\n",
    "        self.EMsteps = config.EMsteps\n",
    "        self.home = config.home\n",
    "        self.prepare_dataset(subsampling_ratio = config.data_subsampling_ratio)\n",
    "        print(f'[save_loc] will save all checkpoints and results to location to {self.home}')\n",
    "\n",
    "    def prepare_dataset(self, subsampling_ratio = None):\n",
    "        self.train_loader, self.test_loader, self.avg_pixel_norm = get_AllenCahn_dataloader(self.config.grid_size, self.config.batch_size, self.config.train_test_split, subsampling_ratio = subsampling_ratio)\n",
    "        self.config.avg_pixel_norm = self.avg_pixel_norm\n",
    "\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def prepare_batch(self, batch, time = 'unif'):\n",
    "        \"\"\"\n",
    "        D: a dictionary of x0, x1, and t, for interpolants\n",
    "        here x0 = noise\n",
    "             x1 = data\n",
    "             t = uniform samples from [0,1]\n",
    "        \"\"\"\n",
    "        target = batch[0]\n",
    "        target = target.to(self.device)\n",
    "\n",
    "        noise = generate_matern_laplace1d(self.config.batch_size, self.config.dim, sigma_sq=self.config.sigma_sq0, length_scale=self.config.length_scale0, s=self.config.s0)\n",
    "        \n",
    "        noise = noise.to(self.device)\n",
    "        D = {'z0': noise, 'z1': target, 'cond': None}\n",
    "        \n",
    "        if time == 'unif':\n",
    "            D['t'] = self.time_dist.sample(sample_shape = (target.shape[0],)).squeeze().type_as(D['z1'])\n",
    "        else:\n",
    "            assert False\n",
    "        D = self.interpolant.It(D)\n",
    "        return D\n",
    "    \n",
    "    def get_optimizer(self, config):\n",
    "        if config.optimizer == \"AdamW\":\n",
    "            print(f'[Optimizer] set up optimizer as {config.optimizer}')\n",
    "            self.lr = self.config.base_lr\n",
    "            return torch.optim.AdamW(self.model.parameters(), lr=self.config.base_lr)\n",
    "    \n",
    "    def target_function(self, D):\n",
    "        target = self.interpolant.Rt(D)  \n",
    "        return target\n",
    "    \n",
    "    def loss_function(self, D):\n",
    "        assert self.model.training\n",
    "        model_out = self.model(D['zt'], D['t'], cond = D['cond'])\n",
    "        target = self.target_function(D)\n",
    "        loss = (model_out - target).pow(2).sum(-1).sum(-1).sum(-1) # using full squared loss here\n",
    "        return loss.mean()\n",
    "    \n",
    "    def clip_grad_norm(self, model, max_grad_norm = 1e+5):\n",
    "        return torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm = max_grad_norm, norm_type = 2.0, error_if_nonfinite = False)\n",
    "\n",
    "    def optimizer_one_step(self, max_grad_norm = 1e+5):\n",
    "        self.clip_grad_norm(self.model, max_grad_norm = max_grad_norm)\n",
    "        if self.global_step % self.config.print_loss_every == 0:\n",
    "            grads = [ param.grad.detach().flatten() for param in self.model.parameters() if param.grad is not None]\n",
    "            norm = torch.cat(grads).norm()\n",
    "            print(f\"[Training] Grad step {self.global_step}. Grad norm:{norm}\")\n",
    "            if self.config.use_wandb:\n",
    "                wandb.log({\"Gradnorm\": norm}, step = self.global_step)\n",
    "        self.optimizer.step()\n",
    "        self.optimizer.zero_grad(set_to_none=True)\n",
    "        self.global_step += 1\n",
    "    \n",
    "    def adjust_learning_rate(self, optimizer):\n",
    "        lr = self.lr\n",
    "        if self.config.cosine_scheduler:\n",
    "            scale = self.global_step / self.config.max_steps\n",
    "            lr *= 0.5 * (1. + math.cos(math.pi * scale))\n",
    "            print(f'[Cosine scheduler] lr is now {lr}')\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = lr\n",
    "    \n",
    "    def fit(self,):\n",
    "        time_begin = time()\n",
    "        print(\"[Training] starting training\")\n",
    "        self.test_model(first_batch_only = True)\n",
    "        \n",
    "        while True:\n",
    "            \n",
    "            if self.global_step >= self.config.max_steps:\n",
    "                break\n",
    "                \n",
    "            for batch in self.train_loader:\n",
    "                if self.global_step % 100 == 0:\n",
    "                    print(f\"[Training] starting step {self.global_step}\")\n",
    "                if self.global_step >= self.config.max_steps:\n",
    "                    break\n",
    "        \n",
    "                self.model.train()\n",
    "                loss = self.loss_function(D = self.prepare_batch(batch))\n",
    "                loss.backward()\n",
    "                self.optimizer_one_step()     \n",
    "    \n",
    "                if self.global_step % self.config.print_loss_every == 0:\n",
    "                    total_mins = (time() - time_begin) / 60\n",
    "                    print(f\"[Training] Grad step {self.global_step}. Loss:{loss.item()}, finished in {total_mins:.2f} minutes\")\n",
    "                    if self.config.use_wandb:\n",
    "                        wandb.log({\"loss\": loss.item()}, step=self.global_step)\n",
    "                \n",
    "                if self.global_step % self.config.save_model_every == 0:\n",
    "                    self.save_model_checkpoint()\n",
    "                if self.global_step % self.config.test_every == 0:\n",
    "                    self.test_model(first_batch_only = True)\n",
    "    \n",
    "                if self.global_step % 100 == 0:\n",
    "                    self.adjust_learning_rate(self.optimizer)\n",
    "    \n",
    "    #### below are testing functions, during the training processes or after training\n",
    "    def save_model_checkpoint(self):\n",
    "        \n",
    "        if not os.path.exists(self.home + f\"checkpoint/{logger.verbose_log_name}\"):\n",
    "            os.makedirs(self.home + f\"checkpoint/{logger.verbose_log_name}\")\n",
    "        save_path = self.home + f\"checkpoint/{logger.verbose_log_name}/model_step{self.global_step}.pth\"\n",
    "        torch.save(self.model.state_dict(), save_path)\n",
    "        print(f'[Saving models] saving models to {save_path}')\n",
    "\n",
    "\n",
    "    def sample_results(self, first_batch_only = True, EMsteps = 200):\n",
    "\n",
    "        test_truth = torch.zeros(self.config.batch_size,1,self.config.dim)\n",
    "        test_input = torch.zeros_like(test_truth)\n",
    "        test_result = torch.zeros_like(test_truth)\n",
    "\n",
    "        \n",
    "        self.model.eval()\n",
    "        time_begin = time()\n",
    "\n",
    "\n",
    "        for batch_idx, batch in enumerate(self.test_loader):\n",
    "            if first_batch_only and batch_idx > 0: break\n",
    "            with torch.no_grad():\n",
    "                D = self.prepare_batch(batch)\n",
    "                test_input = D['z0']\n",
    "                test_truth = D['z1']\n",
    "                test_result = self.sampler.EM(D, self.model, steps = EMsteps)\n",
    "                total_mins = (time() - time_begin) / 60\n",
    "                print(f'finished in {total_mins:.2f} minutes')\n",
    "            \n",
    "\n",
    "        results = torch.cat([test_input, test_truth, test_result], dim = 1)\n",
    "        return results\n",
    "    \n",
    "    def plot_spectra(self, results):\n",
    "\n",
    "        # energy spectrum\n",
    "        if not os.path.exists(self.home + \"images\"):\n",
    "            os.makedirs(self.home + \"images\")\n",
    "        \n",
    "        spectrum_save_name = self.home + f\"images/{logger.verbose_log_name}_spectrum_test.jpg\"\n",
    "        plot_spectra(results[:,1,...].cpu(), results[:,2,...].cpu(), save_name = spectrum_save_name)\n",
    "        print(f\"spectrum plot saved to {spectrum_save_name}\")\n",
    "        \n",
    "        tensor_img = T.ToTensor()(Image.open(spectrum_save_name))\n",
    "\n",
    "        f = lambda x: wandb.Image(x[None,...])\n",
    "        if config.use_wandb:\n",
    "            wandb.log({f'energy spectrum (test )': f(tensor_img)}, step = self.global_step) \n",
    "    \n",
    "    def compute_norm(self, results):\n",
    "        truth = results[:,1,...]\n",
    "        forecast = results[:,2,...]\n",
    "        truth_norm = torch.norm(truth,dim=(1),p='fro').mean() / np.sqrt(self.config.dim)\n",
    "        forecast_norm = torch.norm(forecast,dim=(1),p='fro').mean() / np.sqrt(self.config.dim)\n",
    "        relerr = abs(truth_norm-forecast_norm)/truth_norm\n",
    "        print(f\"[testing norms] truth norm is {truth_norm}, forecast norm is {forecast_norm}, relative err {relerr}\")\n",
    "        if self.config.use_wandb:\n",
    "            wandb.log({f\"norm err\":  relerr}, step = self.global_step)\n",
    "    \n",
    "    def test_model(self, first_batch_only = True):\n",
    "        \n",
    "        test_results = self.sample_results(first_batch_only = first_batch_only, EMsteps = self.EMsteps)\n",
    "\n",
    "        # norm test\n",
    "        self.compute_norm(test_results)\n",
    "        \n",
    "        # spectrum test\n",
    "        self.plot_spectra(test_results)       \n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "635d63c5-a603-4d88-8eac-0c5c2908a1b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "################ logger ################\n",
    "\n",
    "class Loggers:\n",
    "    \"\"\"\n",
    "    self.log_base: date string for naming of logging files\n",
    "    self.log_name: detailed information of the experiment, used for naming of logging files\n",
    "    self.verbose_log_name: more verbose version for naming\n",
    "    \"\"\"\n",
    "    def __init__(self, config):\n",
    "        date = str(datetime.datetime.now())\n",
    "        self.log_base = date[date.find(\"-\"):date.rfind(\".\")].replace(\"-\", \"\").replace(\":\", \"\").replace(\" \", \"_\")\n",
    "        self.log_name =  'grid_size' + str(config.grid_size) + '_' + self.log_base\n",
    "        self.verbose_log_name = 'GaussODE_AllenCahntarget' + '_grid_size' + str(config.grid_size) + 'sz' + str(config.base_lr).replace(\".\",\"\") + 'max' + str(config.max_steps) + '_' + self.log_base\n",
    "        \n",
    "    def is_type_for_logging(self, x):\n",
    "        if isinstance(x, int):\n",
    "            return True\n",
    "        elif isinstance(x, float):\n",
    "            return True\n",
    "        elif isinstance(x, bool):\n",
    "            return True\n",
    "        elif isinstance(x, str):\n",
    "            return True\n",
    "        elif isinstance(x, list):\n",
    "            return True\n",
    "        elif isinstance(x, set):\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    def setup_wandb(self, config):\n",
    "        if config.use_wandb:\n",
    "            config.wandb_run = wandb.init(\n",
    "                    project=config.wandb_project,\n",
    "                    entity=config.wandb_entity,\n",
    "                    resume=None,\n",
    "                    id    =None,\n",
    "                    name = self.verbose_log_name,\n",
    "            )\n",
    "            wandb.run.log_code(\".\")\n",
    "\n",
    "            for key in vars(config):\n",
    "                item = getattr(config, key)\n",
    "                if self.is_type_for_logging(item):\n",
    "                    setattr(wandb.config, key, item)\n",
    "                    print(f'[Config] {key}: {item}')\n",
    "            print(\"[wandb] finished wandb setup\")\n",
    "        else:\n",
    "            print(\"[wandb] not using wandb setup\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3e1d9f0f-fae7-4fa0-9c90-0daa9e3a7f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "################ config ################\n",
    "\n",
    "\n",
    "class Config:\n",
    "    def __init__(self, home = \"./\"):\n",
    "        \n",
    "        # use wandb for logging\n",
    "        self.use_wandb = False\n",
    "        self.wandb_project = 'interpolants_forecasting_new'\n",
    "        self.wandb_entity = 'yifanc96'\n",
    "\n",
    "        self.home = home # for storing checkpoints\n",
    "        \n",
    "        # data\n",
    "        self.seed = 42\n",
    "        self.C = 1\n",
    "        self.grid_size = 64\n",
    "        self.dim = self.grid_size\n",
    "        self.batch_size = 1000\n",
    "        self.train_test_split = 0.9\n",
    "        self.data_subsampling_ratio = 1.0  # use a small amount of data, for sanity check of the code\n",
    "\n",
    "        ## spectrum noise set-up\n",
    "        self.s0 = 1\n",
    "        self.length_scale0 = 1\n",
    "        self.sigma_sq0 = 10\n",
    "        \n",
    "        # training\n",
    "        self.optimizer = 'AdamW'\n",
    "        self.cosine_scheduler = True\n",
    "        self.base_lr = 2*1e-4\n",
    "        self.max_steps = 100\n",
    "        self.t_min_train = 1e-4\n",
    "        self.t_max_train = 1 - 1e-4\n",
    "        self.t_min_sample = 0\n",
    "        self.t_max_sample = 1\n",
    "        self.EMsteps = 200\n",
    "        self.print_loss_every = 10 \n",
    "        self.print_gradnorm_every =  10\n",
    "\n",
    "        self.test_every = 500 # test energy spectrum and norm on reference batch every # iterations\n",
    "        self.save_model_every = 2000 # save model checkpoints every # iterations\n",
    "        \n",
    "        # architecture\n",
    "        self.unet_use_classes = False\n",
    "        self.model_size = 'medium'\n",
    "        if self.model_size == 'small':\n",
    "            self.unet_channels = 8\n",
    "            self.unet_dim_mults = (1, 1, 1, 1)\n",
    "            self.unet_resnet_block_groups = 8\n",
    "            self.unet_learned_sinusoidal_dim = 8\n",
    "            self.unet_attn_dim_head = 8\n",
    "            self.unet_attn_heads = 1\n",
    "            self.unet_learned_sinusoidal_cond = False\n",
    "            self.unet_random_fourier_features = False\n",
    "        \n",
    "        elif self.model_size == 'medium':\n",
    "            self.unet_channels = 32\n",
    "            self.unet_dim_mults = (1, 2, 2, 2)\n",
    "            self.unet_resnet_block_groups = 8\n",
    "            self.unet_learned_sinusoidal_dim = 32\n",
    "            self.unet_attn_dim_head = 32\n",
    "            self.unet_attn_heads = 4\n",
    "            self.unet_learned_sinusoidal_cond = True\n",
    "            self.unet_random_fourier_features = False\n",
    "   \n",
    "        elif self.model_size == 'large':\n",
    "            self.unet_channels = 128\n",
    "            self.unet_dim_mults = (1, 2, 2, 2)\n",
    "            self.unet_resnet_block_groups = 8\n",
    "            self.unet_learned_sinusoidal_dim = 32\n",
    "            self.unet_attn_dim_head = 64\n",
    "            self.unet_attn_heads = 4\n",
    "            self.unet_learned_sinusoidal_cond = True\n",
    "            self.unet_random_fourier_features = False\n",
    "        else:\n",
    "            assert False\n",
    "        self.cond_channels = 0 # no conditioning\n",
    "        # the conditioned term is appended to the input (so the final channel dim = cond_channels + input_channels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6b79d31c-834f-4605-a194-879330b4edd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Argparse] change config data_subsampling_ratio to 1.0\n",
      "[Argparse] change config batch_size to 5000\n",
      "[Argparse] change config base_lr to 0.0002\n",
      "[Argparse] change config grid_size to 64\n",
      "[Argparse] change config dim to 64\n",
      "[Argparse] change config max_steps to 50000\n",
      "[Argparse] change config sample_every to 1000\n",
      "[Argparse] change config test_every to 1000\n",
      "[Argparse] change config save_model_every to 2000\n",
      "[Argparse] change config num_dataset to 1\n",
      "[Argparse] change config use_wandb to False\n",
      "[wandb] not using wandb setup\n",
      "[Network] Num params in main arch for velocity is 1,061,577\n",
      "[Optimizer] set up optimizer as AdamW\n",
      "[Data] raw data shape is (130, 5000, 65)\n",
      "[Data] flattened torchdata, shape is torch.Size([650000, 65])\n",
      "[Data] norm per pixel 0.10495965013442342\n",
      "---- [processing] train_test_split 0.9, num of training 585000, testing 65000\n",
      "[save_loc] will save all checkpoints and results to location to /scratch/yc3400/forecasting/\n"
     ]
    }
   ],
   "source": [
    "def get_parser():\n",
    "    parser = argparse.ArgumentParser(description='PyTorch framework for stochastic interpolants')\n",
    "    parser.add_argument(\"--data_subsampling_ratio\", type=float, default=1.0)\n",
    "    parser.add_argument(\"--batch_size\", type=int, default=5000)\n",
    "    parser.add_argument(\"--base_lr\", type=float, default=2e-4)\n",
    "    parser.add_argument(\"--grid_size\", type=int, default=64)\n",
    "    parser.add_argument(\"--dim\", type=int, default=64)\n",
    "    parser.add_argument(\"--max_steps\", type=int, default=50000)\n",
    "    parser.add_argument(\"--sample_every\", type=int, default=1000)\n",
    "    parser.add_argument(\"--test_every\", type=int, default=1000)\n",
    "    parser.add_argument(\"--save_model_every\", type=int, default=2000)\n",
    "    parser.add_argument(\"--num_dataset\",type=int,default=1)\n",
    "    parser.add_argument('--use_wandb', type = int, default = 0) # 1 is use_wandb, and 0 is not use_wandb\n",
    "    args = parser.parse_args(args=[])\n",
    "    return args\n",
    "\n",
    "random_seed = 0\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(random_seed)\n",
    "args = get_parser()\n",
    "args.use_wandb = bool(args.use_wandb)\n",
    "\n",
    "\n",
    "##### checkpoint and image storage location\n",
    "home = \"/scratch/yc3400/forecasting/\" \n",
    "\n",
    "config = Config(home)\n",
    "for arg in vars(args):\n",
    "    print(f'[Argparse] change config {arg} to {getattr(args, arg)}')\n",
    "    setattr(config, arg, getattr(args, arg))\n",
    "logger = Loggers(config)\n",
    "logger.setup_wandb(config)\n",
    "trainer = Trainer(config)\n",
    "# trainer.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "23d21170-9e2b-4962-bb0b-7a65c07740e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./checkpoints/dim64_spectrum_noise_model_trained50000steps.pth\n"
     ]
    }
   ],
   "source": [
    "##### inference\n",
    "\n",
    "checkpoint_folder = \"./checkpoints/\"\n",
    "# ## dim128-spectrum noise\n",
    "# PATH_file = checkpoint_folder + \"dim128_spectrum_noise_model_trained50000steps.pth\"\n",
    "# ## dim64-spectrum noise\n",
    "PATH_file = checkpoint_folder + \"dim64_spectrum_noise_model_trained50000steps.pth\"\n",
    "# ## dim32-spectrum noise\n",
    "# PATH_file = checkpoint_folder + \"dim32_spectrum_noise_model_trained50000steps.pth\"\n",
    "\n",
    "\n",
    "print(PATH_file)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "cbd4c724-e70f-4467-b55c-245a1a7028b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/state/partition1/job-63044513/ipykernel_1726598/2981232837.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  res_load = torch.load(PATH_file)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Velocity(\n",
       "  (_arch): Unet1D(\n",
       "    (init_conv): Conv1d(1, 32, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "    (time_mlp): Sequential(\n",
       "      (0): RandomOrLearnedSinusoidalPosEmb()\n",
       "      (1): Linear(in_features=17, out_features=128, bias=True)\n",
       "      (2): GELU(approximate='none')\n",
       "      (3): Linear(in_features=128, out_features=128, bias=True)\n",
       "    )\n",
       "    (downs): ModuleList(\n",
       "      (0): ModuleList(\n",
       "        (0-1): 2 x ResnetBlock(\n",
       "          (mlp): Sequential(\n",
       "            (0): SiLU()\n",
       "            (1): Linear(in_features=128, out_features=64, bias=True)\n",
       "          )\n",
       "          (block1): Block(\n",
       "            (proj): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "            (norm): RMSNorm()\n",
       "            (act): SiLU()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (block2): Block(\n",
       "            (proj): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "            (norm): RMSNorm()\n",
       "            (act): SiLU()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (res_conv): Identity()\n",
       "        )\n",
       "        (2): Residual(\n",
       "          (fn): PreNorm(\n",
       "            (fn): LinearAttention(\n",
       "              (to_qkv): Conv1d(32, 384, kernel_size=(1,), stride=(1,), bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Conv1d(128, 32, kernel_size=(1,), stride=(1,))\n",
       "                (1): RMSNorm()\n",
       "              )\n",
       "            )\n",
       "            (norm): RMSNorm()\n",
       "          )\n",
       "        )\n",
       "        (3): Conv1d(32, 32, kernel_size=(4,), stride=(2,), padding=(1,))\n",
       "      )\n",
       "      (1): ModuleList(\n",
       "        (0-1): 2 x ResnetBlock(\n",
       "          (mlp): Sequential(\n",
       "            (0): SiLU()\n",
       "            (1): Linear(in_features=128, out_features=64, bias=True)\n",
       "          )\n",
       "          (block1): Block(\n",
       "            (proj): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "            (norm): RMSNorm()\n",
       "            (act): SiLU()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (block2): Block(\n",
       "            (proj): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "            (norm): RMSNorm()\n",
       "            (act): SiLU()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (res_conv): Identity()\n",
       "        )\n",
       "        (2): Residual(\n",
       "          (fn): PreNorm(\n",
       "            (fn): LinearAttention(\n",
       "              (to_qkv): Conv1d(32, 384, kernel_size=(1,), stride=(1,), bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Conv1d(128, 32, kernel_size=(1,), stride=(1,))\n",
       "                (1): RMSNorm()\n",
       "              )\n",
       "            )\n",
       "            (norm): RMSNorm()\n",
       "          )\n",
       "        )\n",
       "        (3): Conv1d(32, 64, kernel_size=(4,), stride=(2,), padding=(1,))\n",
       "      )\n",
       "      (2): ModuleList(\n",
       "        (0-1): 2 x ResnetBlock(\n",
       "          (mlp): Sequential(\n",
       "            (0): SiLU()\n",
       "            (1): Linear(in_features=128, out_features=128, bias=True)\n",
       "          )\n",
       "          (block1): Block(\n",
       "            (proj): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "            (norm): RMSNorm()\n",
       "            (act): SiLU()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (block2): Block(\n",
       "            (proj): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "            (norm): RMSNorm()\n",
       "            (act): SiLU()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (res_conv): Identity()\n",
       "        )\n",
       "        (2): Residual(\n",
       "          (fn): PreNorm(\n",
       "            (fn): LinearAttention(\n",
       "              (to_qkv): Conv1d(64, 384, kernel_size=(1,), stride=(1,), bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Conv1d(128, 64, kernel_size=(1,), stride=(1,))\n",
       "                (1): RMSNorm()\n",
       "              )\n",
       "            )\n",
       "            (norm): RMSNorm()\n",
       "          )\n",
       "        )\n",
       "        (3): Conv1d(64, 64, kernel_size=(4,), stride=(2,), padding=(1,))\n",
       "      )\n",
       "      (3): ModuleList(\n",
       "        (0-1): 2 x ResnetBlock(\n",
       "          (mlp): Sequential(\n",
       "            (0): SiLU()\n",
       "            (1): Linear(in_features=128, out_features=128, bias=True)\n",
       "          )\n",
       "          (block1): Block(\n",
       "            (proj): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "            (norm): RMSNorm()\n",
       "            (act): SiLU()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (block2): Block(\n",
       "            (proj): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "            (norm): RMSNorm()\n",
       "            (act): SiLU()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (res_conv): Identity()\n",
       "        )\n",
       "        (2): Residual(\n",
       "          (fn): PreNorm(\n",
       "            (fn): LinearAttention(\n",
       "              (to_qkv): Conv1d(64, 384, kernel_size=(1,), stride=(1,), bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Conv1d(128, 64, kernel_size=(1,), stride=(1,))\n",
       "                (1): RMSNorm()\n",
       "              )\n",
       "            )\n",
       "            (norm): RMSNorm()\n",
       "          )\n",
       "        )\n",
       "        (3): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      )\n",
       "    )\n",
       "    (ups): ModuleList(\n",
       "      (0-1): 2 x ModuleList(\n",
       "        (0-1): 2 x ResnetBlock(\n",
       "          (mlp): Sequential(\n",
       "            (0): SiLU()\n",
       "            (1): Linear(in_features=128, out_features=128, bias=True)\n",
       "          )\n",
       "          (block1): Block(\n",
       "            (proj): Conv1d(128, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "            (norm): RMSNorm()\n",
       "            (act): SiLU()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (block2): Block(\n",
       "            (proj): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "            (norm): RMSNorm()\n",
       "            (act): SiLU()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (res_conv): Conv1d(128, 64, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (2): Residual(\n",
       "          (fn): PreNorm(\n",
       "            (fn): LinearAttention(\n",
       "              (to_qkv): Conv1d(64, 384, kernel_size=(1,), stride=(1,), bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Conv1d(128, 64, kernel_size=(1,), stride=(1,))\n",
       "                (1): RMSNorm()\n",
       "              )\n",
       "            )\n",
       "            (norm): RMSNorm()\n",
       "          )\n",
       "        )\n",
       "        (3): Sequential(\n",
       "          (0): Upsample(scale_factor=2.0, mode='nearest')\n",
       "          (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        )\n",
       "      )\n",
       "      (2): ModuleList(\n",
       "        (0-1): 2 x ResnetBlock(\n",
       "          (mlp): Sequential(\n",
       "            (0): SiLU()\n",
       "            (1): Linear(in_features=128, out_features=128, bias=True)\n",
       "          )\n",
       "          (block1): Block(\n",
       "            (proj): Conv1d(96, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "            (norm): RMSNorm()\n",
       "            (act): SiLU()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (block2): Block(\n",
       "            (proj): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "            (norm): RMSNorm()\n",
       "            (act): SiLU()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (res_conv): Conv1d(96, 64, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (2): Residual(\n",
       "          (fn): PreNorm(\n",
       "            (fn): LinearAttention(\n",
       "              (to_qkv): Conv1d(64, 384, kernel_size=(1,), stride=(1,), bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Conv1d(128, 64, kernel_size=(1,), stride=(1,))\n",
       "                (1): RMSNorm()\n",
       "              )\n",
       "            )\n",
       "            (norm): RMSNorm()\n",
       "          )\n",
       "        )\n",
       "        (3): Sequential(\n",
       "          (0): Upsample(scale_factor=2.0, mode='nearest')\n",
       "          (1): Conv1d(64, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        )\n",
       "      )\n",
       "      (3): ModuleList(\n",
       "        (0-1): 2 x ResnetBlock(\n",
       "          (mlp): Sequential(\n",
       "            (0): SiLU()\n",
       "            (1): Linear(in_features=128, out_features=64, bias=True)\n",
       "          )\n",
       "          (block1): Block(\n",
       "            (proj): Conv1d(64, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "            (norm): RMSNorm()\n",
       "            (act): SiLU()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (block2): Block(\n",
       "            (proj): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "            (norm): RMSNorm()\n",
       "            (act): SiLU()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (res_conv): Conv1d(64, 32, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (2): Residual(\n",
       "          (fn): PreNorm(\n",
       "            (fn): LinearAttention(\n",
       "              (to_qkv): Conv1d(32, 384, kernel_size=(1,), stride=(1,), bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Conv1d(128, 32, kernel_size=(1,), stride=(1,))\n",
       "                (1): RMSNorm()\n",
       "              )\n",
       "            )\n",
       "            (norm): RMSNorm()\n",
       "          )\n",
       "        )\n",
       "        (3): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      )\n",
       "    )\n",
       "    (mid_block1): ResnetBlock(\n",
       "      (mlp): Sequential(\n",
       "        (0): SiLU()\n",
       "        (1): Linear(in_features=128, out_features=128, bias=True)\n",
       "      )\n",
       "      (block1): Block(\n",
       "        (proj): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (norm): RMSNorm()\n",
       "        (act): SiLU()\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (block2): Block(\n",
       "        (proj): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (norm): RMSNorm()\n",
       "        (act): SiLU()\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (res_conv): Identity()\n",
       "    )\n",
       "    (mid_attn): Residual(\n",
       "      (fn): PreNorm(\n",
       "        (fn): Attention(\n",
       "          (to_qkv): Conv1d(64, 384, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          (to_out): Conv1d(128, 64, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (norm): RMSNorm()\n",
       "      )\n",
       "    )\n",
       "    (mid_block2): ResnetBlock(\n",
       "      (mlp): Sequential(\n",
       "        (0): SiLU()\n",
       "        (1): Linear(in_features=128, out_features=128, bias=True)\n",
       "      )\n",
       "      (block1): Block(\n",
       "        (proj): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (norm): RMSNorm()\n",
       "        (act): SiLU()\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (block2): Block(\n",
       "        (proj): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (norm): RMSNorm()\n",
       "        (act): SiLU()\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (res_conv): Identity()\n",
       "    )\n",
       "    (final_res_block): ResnetBlock(\n",
       "      (mlp): Sequential(\n",
       "        (0): SiLU()\n",
       "        (1): Linear(in_features=128, out_features=64, bias=True)\n",
       "      )\n",
       "      (block1): Block(\n",
       "        (proj): Conv1d(64, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (norm): RMSNorm()\n",
       "        (act): SiLU()\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (block2): Block(\n",
       "        (proj): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (norm): RMSNorm()\n",
       "        (act): SiLU()\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (res_conv): Conv1d(64, 32, kernel_size=(1,), stride=(1,))\n",
       "    )\n",
       "    (final_conv): Conv1d(32, 1, kernel_size=(1,), stride=(1,))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_load = torch.load(PATH_file)\n",
    "trainer.model.load_state_dict(res_load)\n",
    "trainer.model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "809642b7-8989-4e12-b41b-f243611dc826",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### inference: EM integration\n",
    "\n",
    "# EM_steps = 200\n",
    "# from time import time\n",
    "# time_begin = time()\n",
    "# for batch_idx, batch in enumerate(trainer.test_loader):\n",
    "#     if batch_idx > 0: break\n",
    "#     with torch.no_grad():\n",
    "#         D = trainer.prepare_batch(batch)\n",
    "#         test_input = D['z0']\n",
    "#         test_truth = D['z1']\n",
    "#         test_result = trainer.sampler.EM(D, trainer.model, steps = EM_steps)\n",
    "#         total_mins = (time() - time_begin) / 60\n",
    "#         print(f'finished in {total_mins:.2f} minutes')\n",
    "# results = torch.cat([test_input, test_truth, test_result], dim = 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "782483da-169e-4a22-89d7-c7c0f15ee407",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished in 0.03 minutes\n"
     ]
    }
   ],
   "source": [
    "### inference: RK integration\n",
    "\n",
    "from torchdiffeq import odeint\n",
    "class PFlowRHS(nn.Module):\n",
    "    def __init__(self, drift_b):\n",
    "        super(PFlowRHS, self).__init__()\n",
    "        self.drift_b = drift_b\n",
    "        \n",
    "    def forward(self, t, states):\n",
    "        (zt,) = states\n",
    "        t_arr = torch.ones(zt.shape[0]).type_as(zt) * t\n",
    "        dzt = self.drift_b(zt, t_arr)\n",
    "        return (dzt,)\n",
    "             \n",
    "class PFlowIntegrator:\n",
    "        \n",
    "    def __init__(self):\n",
    "        return        \n",
    "\n",
    "    def __call__(self, drift_b, z0, T_min, T_max, steps, method='dopri5', return_last = True):\n",
    "\n",
    "        rhs = PFlowRHS(drift_b)\n",
    "\n",
    "        t = torch.linspace(\n",
    "            T_min, T_max, steps\n",
    "        ).type_as(z0)\n",
    "\n",
    "        int_args = {\n",
    "            'method': method, \n",
    "            # 'atol': c.integration_atol, \n",
    "            # 'rtol': c.integration_rtol,\n",
    "        }\n",
    "\n",
    "        (z,) = odeint(rhs, (z0,), t, **int_args)\n",
    "        if return_last:\n",
    "            return z[-1].clone()\n",
    "        else:\n",
    "            return z\n",
    "\n",
    "pflow = PFlowIntegrator()\n",
    "\n",
    "t_min_sample = 1e-4\n",
    "t_max_sample = 1-1e-4\n",
    "drift_b = trainer.model\n",
    "time_begin = time()\n",
    "for batch_idx, batch in enumerate(trainer.test_loader):\n",
    "    if batch_idx > 0: break\n",
    "    with torch.no_grad():\n",
    "        D = trainer.prepare_batch(batch)\n",
    "        test_input = D['z0']\n",
    "        test_truth = D['z1']\n",
    "        test_result = out = pflow(\n",
    "            drift_b = drift_b,\n",
    "            z0 = D['z0'],\n",
    "            T_min = t_min_sample,\n",
    "            T_max = t_max_sample,\n",
    "            steps = 5, \n",
    "            method = 'rk4',\n",
    "            return_last = True,)\n",
    "        total_mins = (time() - time_begin) / 60\n",
    "        print(f'finished in {total_mins:.2f} minutes')\n",
    "\n",
    "results = torch.cat([test_input, test_truth, test_result], dim = 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "970ed87b-d069-4aa9-a117-e30a6b028350",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/state/partition1/job-63044513/ipykernel_1726598/3056257141.py:4: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
      "  fourier_amplitudes = np.abs(vorticity_hat)**2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1547b12b37a0>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "kvals, Abins_w0 = get_energy_spectrum1d(results[:,0,...].cpu())\n",
    "kvals, Abins_w1 = get_energy_spectrum1d(results[:,1,...].cpu())\n",
    "kvals, Abins_w2 = get_energy_spectrum1d(results[:,2,...].cpu())\n",
    "\n",
    "fig = plt.figure(figsize=(5,5))\n",
    "plt.plot(kvals, Abins_w0, linewidth=2, marker='o', markersize=8, markevery=2, label = 'noise')\n",
    "plt.plot(kvals, Abins_w1, linewidth=2, marker='o', markersize=8, markevery=2, label = 'truth')\n",
    "plt.plot(kvals, Abins_w2, linewidth=2, marker='o', markersize=8, markevery=2, label = 'generation')\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c3fbb858-74bd-4bda-a397-2aa3735ec5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(Abins_w2, \"AllenCahn-res64-spectrum-noise-RK5.pt\")\n",
    "\n",
    "# torch.save(kvals, \"AllenCahn-res32-kvals.pt\")\n",
    "# torch.save(Abins_w1, \"AllenCahn-res32-truth.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "9beba21e-2159-4115-bec7-67f3d1076faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(Abins_w2, \"AllenCahn-res32-scaled-schedule-RK10.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MYKERNEL",
   "language": "python",
   "name": "my_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
